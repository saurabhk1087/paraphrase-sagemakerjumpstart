{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for fine-tuning on JumpStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first install the `datasets` packages where we will get our dataset from and update our SageMaker SDK version to the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sagemaker datasets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 1. Set-up permissions and SageMaker Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment (not SageMaker Studio or SageMaker Notebook Instances), you will need access to assume an IAM Role with the required permissions for Sagemaker. Find out more about this [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "region = sess.boto_region_name\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 2. Load `sts` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the README file, we will be fine-tuning a model to identify if the question asked by a user is a paraphrase of one of the FAQ's in a list, i.e. if the two questions are semantically equivalent.\n",
    "\n",
    "In order to do this, we want to start with a dataset focused on this task. We will be using the Semantic Textual Similarity (STS) dataset, comprised of pairs of semantically equivalent sentences from different domains (plagiarized sentences, machine translated sentences, and others), along with scores of their similarity in the range of 0-5.  \n",
    "\n",
    "STS dataset is downloaded from\n",
    "[Hugging Face](https://huggingface.co/datasets/stsb_multi_mt). \n",
    "[CC BY-SA 3.0 License](https://creativecommons.org/licenses/by-sa/3.0/legalcode). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=['train+dev+test'])[0]\n",
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be training a model on the task of binary classification - meaning, we want a yes or no answer to the question \"are these two sentences equivalent?\" - we need to threshold the similarity scores into boolean labels. The dataset's [documentation](https://huggingface.co/datasets/stsb_multi_mt) gives us the following guide on what the 0-5 score means: \n",
    "\n",
    "![scores](img/score_meaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure we don't capture ambiguous input data, we will only keep sentence pairs with scores higher than 4 as positive examples, and  lower than 2 as negative examples. We create a new `labels` series with 1's and 0's for the positive and negative examples respectively, the expected label format to fine-tune binary classification models in JumpStart. This will be explained in more detail in the next section of this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext = df[ (df['similarity_score'] >= 4) | (df['similarity_score'] <= 2)]\n",
    "labels = df_ext.apply(lambda x : 1 if x['similarity_score'] >= 4 else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many positive and negative examples we're left with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(labels[labels == 1].index)} positive examples')\n",
    "print(f'There are {len(labels[labels == 0].index)} negative examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more negative than positive examples, but it's not too imbalanced; we will keep this partition of the dataset to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 3. Transform dataset into expected format\n",
    "\n",
    "We will now transform the data into a format that the pre-trained models available on JumpStart - as well as the underlying scripts to fine-tune them - can handle. All of the JumpStart models available for sentence-pair classification expect a common data format, explained below.\n",
    "\n",
    "**Input**: A .csv file named `data.csv`, with the following structure:\n",
    "- Each row of the first column of 'data.csv' should have 0/1 integer class labels.\n",
    "- Each row of the second column should have the corresponding first sentence. \n",
    "- Each row of the third column should have the corresponding second sentence. \n",
    "\n",
    "Below is an example of a `data.csv` file for a random sentence-pair classification dataset, showing values in its first three columns. Note that the file should not have any header.\n",
    "\n",
    "|   |  |  |\n",
    "|---|---|---|\n",
    "|0\t|What is the Grotto at Notre Dame?\t|Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.|\n",
    "|1\t|What is the Grotto at Notre Dame?\t|It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.|\n",
    "|0\t|What sits on top of the Main Building at Notre Dame?\t|Atop the Main Building's gold dome is a golden statue of the Virgin Mary.|\n",
    "|...|...|...|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now transform our dataset into this format. This is quite simple, as we only need to insert our `labels` as the first column of the dataframe, and drop the `similarity_scores` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext.insert(loc=0, column='label', value=labels)\n",
    "df_ext.drop('similarity_score',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is in line with the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can save our `data.csv` file to disk, making sure than the index column and header of the DataFrame are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "file_name = 'data.csv'\n",
    "df_ext.to_csv(f'data/{file_name}', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 4. Upload data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save our data to S3, where our training job will draw it from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'datasets/sts-paraphrase'\n",
    "\n",
    "data_url = sess.upload_data(f'data/{file_name}', sagemaker_session_bucket, f'{prefix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to copy the URL in the output of the following cell, so you can provide to your training job as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go to the NLP lab README to learn how to fine-tune a pre-trained model on our prepared dataset via the JumpStart UI, or alternatively open and run the `jsapi_finetune_paraphrase.ipynb`, which you can find in the same directory as this notebook."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "307046d30e874e46db951879b0020d70d35a4b804063ea90c901d429d46450f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
