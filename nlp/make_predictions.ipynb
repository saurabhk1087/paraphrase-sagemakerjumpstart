{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrase Detection: How to run inference on the endpoint you have created?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some packages the we will need to call our endpoint and process our input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we simulate an input user `question` and define the list of `faqs` that we want to match that question against. You can see in the example below that these are standard questions that might apply to any subscribtion or order-based service, much like Amazon! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 1. Prepare the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Where can I change my contact information?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = [\n",
    "    'How can I change my contact details?',\n",
    "    'Can I change my subscription status at any time of the month?',\n",
    "    'How should I handle missing deliveries?',\n",
    "    'What is the return policy for orders?',\n",
    "    'Will I have access to extra services and products?'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a combination list of question/hypothesis for each FAQ, which the our deployd model will take as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[question,faq] for faq in faqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where can I change my contact information?', 'How can I change my contact details?']\n",
      "['Where can I change my contact information?', 'Can I change my subscription status at any time of the month?']\n",
      "['Where can I change my contact information?', 'How should I handle missing deliveries?']\n",
      "['Where can I change my contact information?', 'What is the return policy for orders?']\n",
      "['Where can I change my contact information?', 'Will I have access to extra services and products?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(pair) for idx,pair in enumerate(pairs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 2. Query the endpoint that you have created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to query the endpoint we have created, get paraphrase predictions for every FAQ, and figure out if any of them (if so, which one) means the same as our user's question!\n",
    "\n",
    "First, let's define some helper functions:\n",
    "\n",
    "- `query_endpoint` uses the Sagemaker Runtime's boto3 client to invoke the endpoint, passing it your encoded input\n",
    "- `parse_response` parses and decodes the reponse from your endpoint, grabbing the relevant keys from the model output\n",
    "- `compute_softmax` is responsible for computing the softmax function over the logits output by the model, turning them into meaningful 0-1 probabilities for each possible label (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you have set a custom name for your endpoint, don't forget to change the value of the <b>your_endpoint</b> variable in the next cell\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global your_endpoint\n",
    "your_endpoint =  'jumpstart-ftc-hf-spc-distilroberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline, bold, unbold = '\\n', '\\033[1m', '\\033[0m'\n",
    "def query_endpoint(encoded_text):\n",
    "    endpoint_name = your_endpoint\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/list-text', Body=encoded_text, Accept='application/json;verbose')\n",
    "    return response\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    logits, predicted_label, labels = model_predictions['probabilities'], model_predictions['predicted_label'], model_predictions['labels']\n",
    "    return logits, predicted_label, labels\n",
    "\n",
    "def compute_softmax(logs):\n",
    "    logits_array = np.array(logs)\n",
    "    probs = list(softmax(logits_array))\n",
    "    return probs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we loop over all the question/FAQ combinations, sending them to our model for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for pair 0:\n",
      "question: Where can I change my contact information?\n",
      "faq: How can I change my contact details?\n",
      "model prediction: [0.0014380110406731113, 0.9985619889593269]\n",
      "predicted label: \u001b[1m1\u001b[0m\n",
      "predicted label: \u001b[1mMatching question!\u001b[0m\n",
      "\n",
      "Prediction for pair 1:\n",
      "question: Where can I change my contact information?\n",
      "faq: Can I change my subscription status at any time of the month?\n",
      "model prediction: [0.9987948971475786, 0.001205102852421532]\n",
      "predicted label: \u001b[1m0\u001b[0m\n",
      "predicted label: \u001b[1mNo relationship\u001b[0m\n",
      "\n",
      "Prediction for pair 2:\n",
      "question: Where can I change my contact information?\n",
      "faq: How should I handle missing deliveries?\n",
      "model prediction: [0.9989790234083225, 0.0010209765916776399]\n",
      "predicted label: \u001b[1m0\u001b[0m\n",
      "predicted label: \u001b[1mNo relationship\u001b[0m\n",
      "\n",
      "Prediction for pair 3:\n",
      "question: Where can I change my contact information?\n",
      "faq: What is the return policy for orders?\n",
      "model prediction: [0.9989804913506942, 0.0010195086493056586]\n",
      "predicted label: \u001b[1m0\u001b[0m\n",
      "predicted label: \u001b[1mNo relationship\u001b[0m\n",
      "\n",
      "Prediction for pair 4:\n",
      "question: Where can I change my contact information?\n",
      "faq: Will I have access to extra services and products?\n",
      "model prediction: [0.998933983708956, 0.0010660162910438912]\n",
      "predicted label: \u001b[1m0\u001b[0m\n",
      "predicted label: \u001b[1mNo relationship\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence_pair in enumerate(pairs):\n",
    "    query_response = query_endpoint(json.dumps(sentence_pair).encode('utf-8'))\n",
    "    logits, predicted_label, labels = parse_response(query_response)\n",
    "    probabilities = compute_softmax(logits)\n",
    "    text_label = 'Matching question!' if predicted_label == 1 else 'No relationship'\n",
    "    print (f\"Prediction for pair {idx}:{newline}\"\n",
    "            f\"question: {sentence_pair[0]}{newline}\"\n",
    "            f\"faq: {sentence_pair[1]}{newline}\"\n",
    "            f\"model prediction: {probabilities}{newline}\"\n",
    "            f\"predicted label: {bold}{predicted_label}{unbold}{newline}\"\n",
    "            f\"predicted label: {bold}{text_label}{unbold}{newline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, all question pairs are correctly classified, with only the first pair being identified as a paraphrase with almost 98% certainty!\n",
    "\n",
    "In fact, we can qualitatively confirm that `Where is the page to change my contact information?` represents the same question as `How can I change my contact details?`"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
